import json
import sys
from urllib import *
import argparse
from urllib.parse import urlparse, urlencode, parse_qs
from urllib.request import  urlopen


YOUTUBE_COMMENT_URL = 'https://www.googleapis.com/youtube/v3/commentThreads'
YOUTUBE_SEARCH_URL = 'https://www.googleapis.com/youtube/v3/search'

def openURL(url,parms):
    sss = urlopen(url + '?' + urlencode(parms))
    data = sss.read()
    sss.close()
    matches = data.decode("utf-8")
    return matches

def load_comments(mat):
    with open ('comm.txt', 'a', encoding="utf-8") as f:
        for item in mat["items"]:
            comment = item["snippet"]["topLevelComment"]
            author = comment["snippet"]["authorDisplayName"]
            text = comment["snippet"]["textDisplay"]
            f.write("Comment by {}: {}".format(author, text))
            if 'replies' in item.keys():
                for reply in item['replies']['comments']:
                    rauthor = reply['snippet']['authorDisplayName']
                    rtext = reply["snippet"]["textDisplay"]

                f.write("\n\tReply by {}: {}".format(rauthor, rtext), "\n")
        f.close()

def get_video_comment():
    parser = argparse.ArgumentParser()
    vid = str()
    videourl="ENTER URL video"
    key="YOURAPIKEY"
    max=100
    try:
        video_id = urlparse(str(videourl))
        q = parse_qs(video_id.query)
        vid = q["v"][0]
    except:
        print("Invalid YouTube URL")
    parms = {
                'part': 'snippet,replies',
                'maxResults': max,
                'videoId': vid,
                'textFormat': 'plainText',
                'key': key
            }

    try:
        matches = openURL(YOUTUBE_COMMENT_URL, parms)
        i = 2
        mat = json.loads(matches)
        nextPageToken = mat.get("nextPageToken")
        print("\nPage : 1")
        load_comments(mat)

        while nextPageToken:
            parms.update({'pageToken': nextPageToken})
            matches = openURL(YOUTUBE_COMMENT_URL, parms)
            mat = json.loads(matches)
            nextPageToken = mat.get("nextPageToken")
            print("\nPage : ", i)
            print("------------------------------------------------------------------")
            load_comments(mat)
            i += 1
    except KeyboardInterrupt:
        print("User Aborted the Operation")

    except Exception as e:
      print(e)


get_video_comment()
